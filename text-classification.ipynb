{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031f0f16",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:20.650979Z",
     "iopub.status.busy": "2022-08-27T18:50:20.650493Z",
     "iopub.status.idle": "2022-08-27T18:50:20.674139Z",
     "shell.execute_reply": "2022-08-27T18:50:20.672826Z"
    },
    "papermill": {
     "duration": 0.036399,
     "end_time": "2022-08-27T18:50:20.677703",
     "exception": false,
     "start_time": "2022-08-27T18:50:20.641304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweettxt/tweet.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5561a55",
   "metadata": {
    "papermill": {
     "duration": 0.006141,
     "end_time": "2022-08-27T18:50:20.691029",
     "exception": false,
     "start_time": "2022-08-27T18:50:20.684888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data Preprocessing:Pre-processing includes three primary steps. First step is Tokenization. It is the process of tokenizing each word in the sentence. Second step is Stemming and lemmatization. It is the process of achieving the root form of the derived words in the sentence, the words are further converted into present tense format. Third Step is The Removal of stop words. It is the process of removing the unnecessary words in the document, the commonly considered stop words include (the, a, an, in etc.,) these are some words that make no sense in the sentence.\n",
    "Baseline: For our baselines, we have mentioned the scores acquired by the LSTM model. Utilised Semantic, lexicon-based aspects and sarcasm indicators to carry out two binary classification tasks: one for sarcastic label 1 and one for non-sarcastic label 0.\n",
    "Trained a Logistic Regression and Recurrent Neural Network (with LSTM layer) methods to carry out classification of Ironic and Sarcastic Tweets using Natural Language Processing. Pre-processing of the text data and word vectorisation was required before training these methods using TensorFlow. Evaluat the methods' performance based on Precision, Recall, and F-Scores. The sequential method has produced accuracy over 60% for training and test datasets before impoved the Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767f48",
   "metadata": {
    "papermill": {
     "duration": 0.005933,
     "end_time": "2022-08-27T18:50:20.703226",
     "exception": false,
     "start_time": "2022-08-27T18:50:20.697293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Improved Model:\n",
    "The above examination, the Keras model was overfitting. The model was performing reasonable on train data but was performing badly on test data. Calculating metric was also poor. The one of reasons for this poor performace was the pre-processing of data and the structure of the method. The preprocessing only changed string into lowercase and then generating tokens. The model had Stochastic Gradient Descent optimizer and did not have dropout layer. With imporoved model by adding Dropout layer as it randomly ignores the nodes and therefore avoides overfitting. By using the hing loss function in the model for better results because hinge loss works well for the binary classifcation.\n",
    "Using Adaptive optimizer \"adam\". Preprocess the data and removing the stopwords, punctuations and special characters. To avoid any problem in tokenzing for the keras model Removing numbers from the data. The model performance was not improving very good but evaluation metricthe improved noticeably.\n",
    "\n",
    "Achieved accuracy on the training dataset %99.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1a3d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:20.717426Z",
     "iopub.status.busy": "2022-08-27T18:50:20.717014Z",
     "iopub.status.idle": "2022-08-27T18:50:29.745404Z",
     "shell.execute_reply": "2022-08-27T18:50:29.744254Z"
    },
    "papermill": {
     "duration": 9.038759,
     "end_time": "2022-08-27T18:50:29.748229",
     "exception": false,
     "start_time": "2022-08-27T18:50:20.709470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " #Required Imports\n",
    "# %tensorflow_version 2.x\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Embedding\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14fa874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:29.766374Z",
     "iopub.status.busy": "2022-08-27T18:50:29.765312Z",
     "iopub.status.idle": "2022-08-27T18:50:29.809477Z",
     "shell.execute_reply": "2022-08-27T18:50:29.807501Z"
    },
    "papermill": {
     "duration": 0.057559,
     "end_time": "2022-08-27T18:50:29.813187",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.755628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tweet index  Label                                         Tweet text\n",
      "0            1      1  Sweet United Nations video. Just in time for C...\n",
      "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
      "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
      "3            4      0                3 episodes left I'm dying over here\n",
      "4            5      1  I can't breathe! was chosen as the most notabl...\n",
      "Tweet index    False\n",
      "Label          False\n",
      "Tweet text     False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Loading data from csv file\n",
    "data = pd.read_csv('../input/tweettxt/tweet.txt', sep='\\t')\n",
    "print(data.head())\n",
    "# It is always better to check the null values in the dataset first.\n",
    "print(data.isnull().any(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a7ab6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:29.829462Z",
     "iopub.status.busy": "2022-08-27T18:50:29.829030Z",
     "iopub.status.idle": "2022-08-27T18:50:29.852240Z",
     "shell.execute_reply": "2022-08-27T18:50:29.851200Z"
    },
    "papermill": {
     "duration": 0.034088,
     "end_time": "2022-08-27T18:50:29.854760",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.820672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading the File\n",
    "dataset = pd.read_csv('../input/tweettxt/tweet.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9103c920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:29.869818Z",
     "iopub.status.busy": "2022-08-27T18:50:29.869377Z",
     "iopub.status.idle": "2022-08-27T18:50:29.928583Z",
     "shell.execute_reply": "2022-08-27T18:50:29.926960Z"
    },
    "papermill": {
     "duration": 0.069731,
     "end_time": "2022-08-27T18:50:29.931307",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.861576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Vocabulary: 17052\n",
      "Total Number of Positive Examples: 1901\n",
      "Total Number of Negative Examples: 1916\n"
     ]
    }
   ],
   "source": [
    "#Loding the file and storing in the dataframe\n",
    "data = pd.read_csv('../input/tweettxt/tweet.txt', sep='\\t')\n",
    "#Renaming the columns\n",
    "data.columns = ['Tweet_index', 'Label','Tweet_text']\n",
    "#Storing the Tweet Text as list\n",
    "corpusTweet = data['Tweet_text'].tolist() #Storing the lables as sentiments\n",
    "sentiments = data['Label']\n",
    "positiveExample = 0\n",
    "negativeExample = 0\n",
    "#Get all the words in one list\n",
    "wordList =[]\n",
    "for words in corpusTweet:\n",
    "    wordList.append(words.lower().strip().split())\n",
    "wordList = list(itertools.chain.from_iterable(wordList)) #Set is fetching the unique words and we add it to the vocabulary\n",
    "vocabulary = set(wordList)\n",
    "vocabulary_len = len(vocabulary)\n",
    "for i in range(len(sentiments)):\n",
    "    if(sentiments[i] == 1):\n",
    "        positiveExample = positiveExample + 1\n",
    "    else:\n",
    "        negativeExample = negativeExample + 1\n",
    "print(\"Size of the Vocabulary:\",vocabulary_len)\n",
    "print(\"Total Number of Positive Examples:\",positiveExample)\n",
    "print(\"Total Number of Negative Examples:\",negativeExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6786a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:29.946532Z",
     "iopub.status.busy": "2022-08-27T18:50:29.945964Z",
     "iopub.status.idle": "2022-08-27T18:50:29.954135Z",
     "shell.execute_reply": "2022-08-27T18:50:29.952260Z"
    },
    "papermill": {
     "duration": 0.019229,
     "end_time": "2022-08-27T18:50:29.957179",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.937950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use the data for train test split\n",
    "data_x = data['Tweet_text']\n",
    "labels_y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6c1377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:29.974618Z",
     "iopub.status.busy": "2022-08-27T18:50:29.974011Z",
     "iopub.status.idle": "2022-08-27T18:50:29.980202Z",
     "shell.execute_reply": "2022-08-27T18:50:29.978910Z"
    },
    "papermill": {
     "duration": 0.018788,
     "end_time": "2022-08-27T18:50:29.983418",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.964630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function calculating precision recall and F-Measure\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    #Accept Actual values and Predicting values to calculate metric scores\n",
    "    precision_score = metrics.precision_score(y_true, y_pred)\n",
    "    recall_score = metrics.recall_score(y_true, y_pred)\n",
    "    f1_score = metrics.f1_score(y_true, y_pred)\n",
    "    return precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a11040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:30.006332Z",
     "iopub.status.busy": "2022-08-27T18:50:30.005528Z",
     "iopub.status.idle": "2022-08-27T18:50:30.567300Z",
     "shell.execute_reply": "2022-08-27T18:50:30.565940Z"
    },
    "papermill": {
     "duration": 0.575773,
     "end_time": "2022-08-27T18:50:30.569972",
     "exception": false,
     "start_time": "2022-08-27T18:50:29.994199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert words into tokens(numbers)\n",
    "vectorizer_word = CountVectorizer(ngram_range=(1,1))\n",
    "vectorizer_word.fit(corpusTweet)\n",
    "#transform output to array\n",
    "data_x = vectorizer_word.transform(corpusTweet).toarray() #Split train test data\n",
    "#splliting 70% for training and 30% for test\n",
    "train_X, test_X, y_train, y_test = train_test_split(data_x,labels_y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908291a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:30.585687Z",
     "iopub.status.busy": "2022-08-27T18:50:30.584869Z",
     "iopub.status.idle": "2022-08-27T18:50:34.938952Z",
     "shell.execute_reply": "2022-08-27T18:50:34.937540Z"
    },
    "papermill": {
     "duration": 4.366376,
     "end_time": "2022-08-27T18:50:34.943217",
     "exception": false,
     "start_time": "2022-08-27T18:50:30.576841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison, Recall and F-Measure Score for Logistic Regression is:\n",
      "(0.6492248062015504, 0.5982142857142857, 0.6226765799256505)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression has the log linear model\n",
    "logReg = LogisticRegression()\n",
    "#Train the model on train data\n",
    "logReg.fit(train_X, y_train)\n",
    "#Create list for storing the predictions\n",
    "predictions = []\n",
    "for i in test_X:\n",
    "#predict all the test data\n",
    "    predictions.append(logReg.predict(i.reshape(1,-1)))\n",
    "#call the defined metrics function to get the Precison recall and F-measure score\n",
    "print(\"Precison, Recall and F-Measure Score for Logistic Regression is:\")\n",
    "print(calculate_metrics(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77d88be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:34.981018Z",
     "iopub.status.busy": "2022-08-27T18:50:34.980293Z",
     "iopub.status.idle": "2022-08-27T18:50:34.995667Z",
     "shell.execute_reply": "2022-08-27T18:50:34.994301Z"
    },
    "papermill": {
     "duration": 0.038856,
     "end_time": "2022-08-27T18:50:34.999667",
     "exception": false,
     "start_time": "2022-08-27T18:50:34.960811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671 1146\n"
     ]
    }
   ],
   "source": [
    "#Maximum Lenght of the Output Dimension\n",
    "max_Lenght = 128\n",
    "#Get the data for Test and Train split\n",
    "dataXnn = data['Tweet_text'].tolist()\n",
    "labelsYnn = data['Label'].tolist()\n",
    "#Split the data in to test and train with 70% for train and 30% for test.\n",
    "trainX_nn, testX_nn, trainY_nn, testY_nn = train_test_split(dataXnn,labelsYnn,test_size=0.3, shuffle=True)\n",
    "print(len(trainX_nn), len(testX_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50f8022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:35.030689Z",
     "iopub.status.busy": "2022-08-27T18:50:35.030271Z",
     "iopub.status.idle": "2022-08-27T18:50:35.198901Z",
     "shell.execute_reply": "2022-08-27T18:50:35.197642Z"
    },
    "papermill": {
     "duration": 0.184764,
     "end_time": "2022-08-27T18:50:35.201700",
     "exception": false,
     "start_time": "2022-08-27T18:50:35.016936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocess data for Keras Model\n",
    "#Convert class vector to binary class matrix.\n",
    "trainY_nn = to_categorical(trainY_nn)\n",
    "#Convert sentences into tokens as an input for the model\n",
    "tokenizer = Tokenizer(num_words = vocabulary_len)\n",
    "#Vectorize the corpus\n",
    "#Update internal vocabulary based on a list of texts\n",
    "tokenizer.fit_on_texts(trainX_nn)\n",
    "#Store Label test data before preprocessing into another list so that it can be used later with original format\n",
    "testY_nn1 = testY_nn\n",
    "#Transform each text in texts to a sequence of integers\n",
    "trainX_nn = tokenizer.texts_to_sequences(trainX_nn)\n",
    "#Padding sequences to the same length. The smaller sententces will be padded with 0 and thus model understands it\n",
    "trainX_nn = pad_sequences(trainX_nn, maxlen = max_Lenght)\n",
    "#Transform each text in texts to a sequence of integers for test data\n",
    "testX_nn = tokenizer.texts_to_sequences(testX_nn)\n",
    "#Padding sequences to the same length for test data\n",
    "testX_nn = pad_sequences(testX_nn, maxlen = max_Lenght)\n",
    "testY_nn = to_categorical(testY_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9ac8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:35.217744Z",
     "iopub.status.busy": "2022-08-27T18:50:35.217311Z",
     "iopub.status.idle": "2022-08-27T18:50:35.685023Z",
     "shell.execute_reply": "2022-08-27T18:50:35.683318Z"
    },
    "papermill": {
     "duration": 0.479354,
     "end_time": "2022-08-27T18:50:35.687820",
     "exception": false,
     "start_time": "2022-08-27T18:50:35.208466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 18:50:35.267561: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         2182656   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 2,274,458\n",
      "Trainable params: 2,274,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Keras Model\n",
    "#Sequential Model\n",
    "#Embedd layer for similarity in words\n",
    "#This layer encodes the input sequence into a sequence of dense vectors.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabulary_len, max_Lenght), ])\n",
    "#Implement LSTM layer\n",
    "#LSTM layer uses gates to control the memorizing process #transforms the vector sequence into a single vector of size comtaining sequence information.\n",
    "model.add(tf.keras.layers.LSTM(100))\n",
    "#Dense layer with activation function as softmax\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "#Compile the model with binary crossentropy loss functions and stochastic gradient descent optimizer\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics = ['accuracy'])\n",
    "#Summerize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efcaf44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:50:35.703966Z",
     "iopub.status.busy": "2022-08-27T18:50:35.703474Z",
     "iopub.status.idle": "2022-08-27T18:56:30.379055Z",
     "shell.execute_reply": "2022-08-27T18:56:30.378077Z"
    },
    "papermill": {
     "duration": 354.686534,
     "end_time": "2022-08-27T18:56:30.381562",
     "exception": false,
     "start_time": "2022-08-27T18:50:35.695028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 18:50:35.763105: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 38s 134ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6938 - val_accuracy: 0.4686\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.6930 - accuracy: 0.5107 - val_loss: 0.6938 - val_accuracy: 0.4686\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6926 - accuracy: 0.5107 - val_loss: 0.6935 - val_accuracy: 0.4703\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6925 - accuracy: 0.5118 - val_loss: 0.6938 - val_accuracy: 0.4686\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6922 - accuracy: 0.5241 - val_loss: 0.6939 - val_accuracy: 0.4686\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 35s 129ms/step - loss: 0.6920 - accuracy: 0.5099 - val_loss: 0.6933 - val_accuracy: 0.4738\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.6918 - accuracy: 0.5241 - val_loss: 0.6937 - val_accuracy: 0.4695\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6939 - val_accuracy: 0.4686\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 0.6913 - accuracy: 0.5103 - val_loss: 0.6933 - val_accuracy: 0.4764\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 35s 132ms/step - loss: 0.6910 - accuracy: 0.5286 - val_loss: 0.6926 - val_accuracy: 0.5157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9818eb0950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model with 10 batch size and 10 iterations\n",
    "model.fit(x =trainX_nn, y=trainY_nn ,epochs = 10, batch_size = 10,\n",
    "    validation_data=(testX_nn, testY_nn) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66db9cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:30.722917Z",
     "iopub.status.busy": "2022-08-27T18:56:30.721881Z",
     "iopub.status.idle": "2022-08-27T18:56:30.760909Z",
     "shell.execute_reply": "2022-08-27T18:56:30.759823Z"
    },
    "papermill": {
     "duration": 0.212422,
     "end_time": "2022-08-27T18:56:30.763503",
     "exception": false,
     "start_time": "2022-08-27T18:56:30.551081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Saving the Model\n",
    "model.save('Final_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68896d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:31.100524Z",
     "iopub.status.busy": "2022-08-27T18:56:31.100123Z",
     "iopub.status.idle": "2022-08-27T18:56:32.967860Z",
     "shell.execute_reply": "2022-08-27T18:56:32.966894Z"
    },
    "papermill": {
     "duration": 2.039398,
     "end_time": "2022-08-27T18:56:32.970133",
     "exception": false,
     "start_time": "2022-08-27T18:56:30.930735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison, Recall and F-Measure Score is:\n",
      "(0.49096385542168675, 0.9106145251396648, 0.6379647749510763)\n"
     ]
    }
   ],
   "source": [
    "#Predicting the classes for the test data and storing in the list\n",
    "predictRNN = np.argmax(model.predict(testX_nn),axis =1)\n",
    "#Fecth the Metric results\n",
    "print(\"Precison, Recall and F-Measure Score is:\")\n",
    "print(calculate_metrics(testY_nn1,predictRNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad360512",
   "metadata": {
    "papermill": {
     "duration": 0.16807,
     "end_time": "2022-08-27T18:56:33.390281",
     "exception": false,
     "start_time": "2022-08-27T18:56:33.222211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Improved Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "678c4142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:33.731956Z",
     "iopub.status.busy": "2022-08-27T18:56:33.731205Z",
     "iopub.status.idle": "2022-08-27T18:56:34.618181Z",
     "shell.execute_reply": "2022-08-27T18:56:34.616937Z"
    },
    "papermill": {
     "duration": 1.061451,
     "end_time": "2022-08-27T18:56:34.620763",
     "exception": false,
     "start_time": "2022-08-27T18:56:33.559312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Updating Vocabulary: 12940\n"
     ]
    }
   ],
   "source": [
    "#Data Enhancement\n",
    "data = pd.read_csv('../input/tweettxt/tweet.txt', sep='\\t')\n",
    "data.columns = ['Tweet_index', 'Label','Tweet_text']\n",
    "#Data preprocess and remove the unwanted data\n",
    "#Removing Numbers\n",
    "data['Tweet_text'] = data['Tweet_text'].str.replace('\\d+', '') #Removing -- character\n",
    "data['Tweet_text'] = data['Tweet_text'].str.replace(\"--\", '') #Removing Punctuations\n",
    "data['Tweet_text'] = data['Tweet_text'].str.replace('[^\\w\\s]','')\n",
    "#Lowercase and splitting sentences into tokens\n",
    "data['Tweet_text'] = data['Tweet_text'].str.lower()\n",
    "#Removing Stop words\n",
    "data['Tweet_text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "corpusTweet = data['Tweet_text'].tolist()\n",
    "wordList =[]\n",
    "for words in corpusTweet:\n",
    "      #print(words)\n",
    "    wordList.extend(words.split())\n",
    "#wordList = list(itertools.chain.from_iterable(wordList))\n",
    "vocabulary = set(wordList)\n",
    "vocabulary_len = len(vocabulary)\n",
    "#After preprocessing the data, the updating vacabluary has less words\n",
    "print(\"Size of the Updating Vocabulary:\",vocabulary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d91186e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:34.960544Z",
     "iopub.status.busy": "2022-08-27T18:56:34.960143Z",
     "iopub.status.idle": "2022-08-27T18:56:35.047612Z",
     "shell.execute_reply": "2022-08-27T18:56:35.046129Z"
    },
    "papermill": {
     "duration": 0.261269,
     "end_time": "2022-08-27T18:56:35.050381",
     "exception": false,
     "start_time": "2022-08-27T18:56:34.789112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671 1146\n"
     ]
    }
   ],
   "source": [
    "data_x_nn = data['Tweet_text'].tolist()\n",
    "labels_y = data['Label'].tolist()\n",
    "#Maximum Lenght of the Output Dimension\n",
    "max_Lenght = 128\n",
    "#Get the data for Test Train split\n",
    "data_x_nn = data['Tweet_text'].tolist()\n",
    "labels_y_nn = data['Label'].tolist()\n",
    "#Split the data in to test and train with 70% for train and 30% for test.\n",
    "trainX_nn, testX_nn, trainY_nn, testY_nn = train_test_split(data_x_nn,labels_y_nn,test_size=0.3, shuffle=True)\n",
    "print(len(trainX_nn), len(testX_nn))\n",
    "#Preproces data for Keras Model\n",
    "#Convert class vector to binary class matrix.\n",
    "trainY_nn = to_categorical(trainY_nn)\n",
    "#Converting sentences into tokens as an input for the model\n",
    "tokenizer = Tokenizer(num_words = vocabulary_len)\n",
    "#Vectorize the corpus\n",
    "#Update internal vocabulary based on a list of texts\n",
    "tokenizer.fit_on_texts(trainX_nn)\n",
    "#Store Label test data before preprocessing into another list so that it can be used later with original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4e1d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:35.389532Z",
     "iopub.status.busy": "2022-08-27T18:56:35.389108Z",
     "iopub.status.idle": "2022-08-27T18:56:35.474078Z",
     "shell.execute_reply": "2022-08-27T18:56:35.472873Z"
    },
    "papermill": {
     "duration": 0.258982,
     "end_time": "2022-08-27T18:56:35.477049",
     "exception": false,
     "start_time": "2022-08-27T18:56:35.218067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testY_nn1 = testY_nn\n",
    "#Transform each text in texts to a sequence of integers\n",
    "trainX_nn = tokenizer.texts_to_sequences(trainX_nn)\n",
    "#Padding sequences to the same length. The smaller sententces will be padded with 0 and thus model understands it\n",
    "trainX_nn = pad_sequences(trainX_nn, maxlen = max_Lenght)\n",
    "#Transform each text in texts to a sequence of integers for test data\n",
    "testX_nn = tokenizer.texts_to_sequences(testX_nn)\n",
    "#Padding sequences to the same length for test data\n",
    "testX_nn = pad_sequences(testX_nn, maxlen = max_Lenght)\n",
    "testY_nn = to_categorical(testY_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b65a18da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:35.817386Z",
     "iopub.status.busy": "2022-08-27T18:56:35.816974Z",
     "iopub.status.idle": "2022-08-27T18:56:36.330210Z",
     "shell.execute_reply": "2022-08-27T18:56:36.328619Z"
    },
    "papermill": {
     "duration": 0.687135,
     "end_time": "2022-08-27T18:56:36.332943",
     "exception": false,
     "start_time": "2022-08-27T18:56:35.645808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1656320   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 100)         91600     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,828,522\n",
      "Trainable params: 1,828,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential Model with Embedding layer just like above\n",
    "model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocabulary_len, max_Lenght),\n",
    "])\n",
    "#Add two LSTM layers one returns the sequence other doesnt\n",
    "model.add(tf.keras.layers.LSTM(100, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(100, return_sequences=False)) #Drouput layer is used to avoid overfitting. Randomly ignores the nodes from the layer and thus overfitting is avoided\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "#Activation function used is softmax\n",
    "model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "#Use Hinge loss as it is better for binary classification (From lecture 3 slides) & Adaptive Adam optimizer\n",
    "model.compile(loss = 'squared_hinge', optimizer=tf.keras.optimizers.Adam(1e-4), metrics = ['accuracy'])\n",
    "#Summary of Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2d8b2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T18:56:36.671084Z",
     "iopub.status.busy": "2022-08-27T18:56:36.670695Z",
     "iopub.status.idle": "2022-08-27T19:08:23.748242Z",
     "shell.execute_reply": "2022-08-27T19:08:23.747091Z"
    },
    "papermill": {
     "duration": 707.250713,
     "end_time": "2022-08-27T19:08:23.750729",
     "exception": false,
     "start_time": "2022-08-27T18:56:36.500016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 75s 264ms/step - loss: 1.0000 - accuracy: 0.4994 - val_loss: 1.0000 - val_accuracy: 0.5244\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.9973 - accuracy: 0.5335 - val_loss: 0.9982 - val_accuracy: 0.4904\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 69s 259ms/step - loss: 0.9589 - accuracy: 0.6189 - val_loss: 0.9863 - val_accuracy: 0.5558\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 71s 264ms/step - loss: 0.7748 - accuracy: 0.8233 - val_loss: 1.0239 - val_accuracy: 0.6274\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 70s 262ms/step - loss: 0.6349 - accuracy: 0.9176 - val_loss: 1.0637 - val_accuracy: 0.5969\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 69s 258ms/step - loss: 0.5662 - accuracy: 0.9659 - val_loss: 1.2104 - val_accuracy: 0.5951\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 70s 260ms/step - loss: 0.5362 - accuracy: 0.9783 - val_loss: 1.2762 - val_accuracy: 0.6126\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 71s 266ms/step - loss: 0.5206 - accuracy: 0.9906 - val_loss: 1.3827 - val_accuracy: 0.5960\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 71s 264ms/step - loss: 0.5122 - accuracy: 0.9940 - val_loss: 1.5918 - val_accuracy: 0.6003\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 71s 266ms/step - loss: 0.5095 - accuracy: 0.9970 - val_loss: 1.5457 - val_accuracy: 0.6012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97c874f810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Train\n",
    "model.fit(x =trainX_nn, y=trainY_nn ,epochs = 10, batch_size = 10,\n",
    "    validation_data=(testX_nn, testY_nn) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44e7886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T19:08:24.425283Z",
     "iopub.status.busy": "2022-08-27T19:08:24.423837Z",
     "iopub.status.idle": "2022-08-27T19:08:29.025087Z",
     "shell.execute_reply": "2022-08-27T19:08:29.023011Z"
    },
    "papermill": {
     "duration": 4.940171,
     "end_time": "2022-08-27T19:08:29.028538",
     "exception": false,
     "start_time": "2022-08-27T19:08:24.088367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1459624  0.37634978]\n",
      " [0.50435996 0.04662997]\n",
      " [3.1004777  0.        ]\n",
      " ...\n",
      " [1.241954   0.        ]\n",
      " [0.         2.0187237 ]\n",
      " [0.         0.8379101 ]]\n"
     ]
    }
   ],
   "source": [
    "ENpredictRNN =model.predict(testX_nn)\n",
    "classes_x=np.argmax(ENpredictRNN,axis=1)\n",
    "print(ENpredictRNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1101.93291,
   "end_time": "2022-08-27T19:08:32.198581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-27T18:50:10.265671",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
